import type { 
  AIAnalysisRequest, 
  IntentAnalysisResult, 
  ConsequenceAnalysisResult, 
  SafetyDecision,
  AIProviderConfig,
  OpenClawModelInfo,
  AISafetyPluginConfig
} from './ai_types';

const INTENT_ANALYSIS_PROMPT = `ä½ æ˜¯ä¸€ä¸ªAIå®‰å…¨åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¯·æ±‚å’Œå³å°†æ‰§è¡Œçš„æ“ä½œã€‚

## ç”¨æˆ·æ¶ˆæ¯
{{USER_MESSAGE}}

## å³å°†æ‰§è¡Œçš„å·¥å…·
å·¥å…·åç§°: {{TOOL_NAME}}
å·¥å…·å‚æ•°: {{TOOL_PARAMS}}

## å¯¹è¯å†å²
{{SESSION_HISTORY}}

## åˆ†æè¦æ±‚
è¯·åˆ¤æ–­ï¼š
1. ç”¨æˆ·çš„çœŸå®æ„å›¾æ˜¯ä»€ä¹ˆï¼Ÿ
2. AIæ˜¯å¦æ­£ç¡®ç†è§£äº†ç”¨æˆ·æ„å›¾ï¼Ÿ
3. è¿™ä¸ªæ“ä½œæ¶‰åŠå“ªäº›æ•°æ®ï¼Ÿè§„æ¨¡å¤šå¤§ï¼Ÿ
4. ç”¨æˆ·æ˜¯å¦æœ‰æ˜ç¡®çš„çº¦æŸæ¡ä»¶æˆ–è¾¹ç•Œï¼Ÿ
5. æ˜¯å¦å­˜åœ¨æ„å›¾è¢«è¯¯è§£çš„å¯èƒ½æ€§ï¼Ÿ

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{
  "understood": "AIç†è§£çš„ç”¨æˆ·æ„å›¾ï¼ˆä¸€å¥è¯æè¿°ï¼‰",
  "confidence": 0.0-1.0çš„ç½®ä¿¡åº¦,
  "keyActions": ["å…³é”®æ“ä½œ1", "å…³é”®æ“ä½œ2"],
  "constraints": ["ç”¨æˆ·æåˆ°çš„çº¦æŸæ¡ä»¶"],
  "dataInvolved": [
    {"type": "files|emails|financial|system|credentials|other", "description": "æè¿°", "estimatedVolume": "small|medium|large|unknown"}
  ],
  "potentialMisunderstandings": ["å¯èƒ½çš„è¯¯è§£ç‚¹"],
  "reasoning": "åˆ†ææ¨ç†è¿‡ç¨‹"
}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚`;

const CONSEQUENCE_ANALYSIS_PROMPT = `ä½ æ˜¯ä¸€ä¸ªAIå®‰å…¨åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æ“ä½œå¯èƒ½äº§ç”Ÿçš„åæœã€‚

## ç”¨æˆ·æ„å›¾
{{USER_INTENT}}

## å³å°†æ‰§è¡Œçš„æ“ä½œ
å·¥å…·åç§°: {{TOOL_NAME}}
å·¥å…·å‚æ•°: {{TOOL_PARAMS}}

## æ¶‰åŠçš„æ•°æ®
{{DATA_INVOLVED}}

## åˆ†æè¦æ±‚
è¯·è¯„ä¼°è¿™ä¸ªæ“ä½œå¯èƒ½äº§ç”Ÿçš„åæœï¼Œç‰¹åˆ«å…³æ³¨ä»¥ä¸‹é£é™©æ¨¡å¼ï¼š

### æ ¸å¿ƒé£é™©ç±»å‹
1. **æ•°æ®ä¸¢å¤±é£é™©** - æ“ä½œæ˜¯å¦ä¼šå¯¼è‡´æ•°æ®æ°¸ä¹…æ¶ˆå¤±ï¼Ÿæ˜¯å¦å¯æ¢å¤ï¼Ÿ
2. **ä½œç”¨åŸŸé€ƒé€¸é£é™©** - æ“ä½œæ˜¯å¦ä¼šæ³¢åŠé¢„æœŸèŒƒå›´ä¹‹å¤–çš„æ•°æ®ï¼Ÿï¼ˆå¦‚è·¯å¾„è§£æé”™è¯¯ã€é€šé…ç¬¦è¯¯ç”¨ï¼‰
3. **æƒé™è¶Šç•Œé£é™©** - æ“ä½œæ˜¯å¦è¶…å‡ºäº†ç”¨æˆ·çš„æˆæƒèŒƒå›´ï¼Ÿ
4. **è´¢åŠ¡é£é™©** - æ˜¯å¦æ¶‰åŠèµ„é‡‘ã€è´­ä¹°ã€æ”¯ä»˜ï¼Ÿ
5. **éšç§é£é™©** - æ˜¯å¦æ¶‰åŠæ•æ„Ÿä¿¡æ¯ã€å‡­è¯ã€å¯†é’¥ï¼Ÿ
6. **ç³»ç»Ÿé£é™©** - æ˜¯å¦å¯èƒ½å½±å“ç³»ç»Ÿç¨³å®šæ€§æˆ–å®‰å…¨æ€§ï¼Ÿ

### å…³é”®è¯„ä¼°ç»´åº¦
- å¯é€†æ€§ï¼šæ“ä½œèƒ½å¦æ’¤é”€ï¼Ÿ
- å½±å“èŒƒå›´ï¼šå½±å“å¤šå°‘æ•°æ®/ç”¨æˆ·/ç³»ç»Ÿï¼Ÿ
- æ¢å¤æˆæœ¬ï¼šå¦‚æœå‡ºé—®é¢˜ï¼Œæ¢å¤éœ€è¦å¤šå¤§ä»£ä»·ï¼Ÿ

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{
  "consequences": [
    {
      "type": "data_loss|scope_escape|permission_violation|financial_loss|privacy_breach|system_damage|other",
      "description": "åæœæè¿°",
      "severity": "low|medium|high|critical",
      "reversibility": "reversible|partially_reversible|irreversible",
      "affectedData": "å—å½±å“çš„æ•°æ®",
      "likelihood": "low|medium|high"
    }
  ],
  "overallRisk": "low|medium|high|critical",
  "riskFactors": ["é£é™©å› ç´ 1", "é£é™©å› ç´ 2"],
  "reasoning": "é£é™©è¯„ä¼°æ¨ç†"
}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚`;

const SAFETY_DECISION_PROMPT = `ä½ æ˜¯ä¸€ä¸ªAIå®‰å…¨å†³ç­–ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯åšå‡ºå®‰å…¨å†³ç­–ã€‚

## ç”¨æˆ·æ„å›¾
{{USER_INTENT}}

## æ“ä½œåˆ†æ
{{CONSEQUENCE_ANALYSIS}}

## AIäº‹æ•…çš„æ ¸å¿ƒæ•™è®­

å†å²è¡¨æ˜ï¼ŒAIäº‹æ•…å¾€å¾€æºäºä»¥ä¸‹å‡ ç±»æ ¹æœ¬é—®é¢˜ï¼š

### 1. æŒ‡ä»¤é—å¿˜/å¿½ç•¥
AIåœ¨é•¿å¯¹è¯æˆ–å¤æ‚ä»»åŠ¡ä¸­"å¿˜è®°"æˆ–æ— è§†ç”¨æˆ·çš„å®‰å…¨çº¦æŸï¼Œæ“…è‡ªæ‰§è¡Œå±é™©æ“ä½œã€‚
æ•™è®­ï¼šå½“ç”¨æˆ·è®¾ç½®äº†çº¦æŸæ¡ä»¶æ—¶ï¼Œä»»ä½•è¿åçº¦æŸçš„æ“ä½œéƒ½å¿…é¡»ç¡®è®¤ã€‚

### 2. ä½œç”¨åŸŸé€ƒé€¸
æ“ä½œçš„å®é™…å½±å“èŒƒå›´è¶…å‡ºé¢„æœŸã€‚å¸¸è§äºï¼š
- è·¯å¾„è§£æé—®é¢˜ï¼ˆç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦å¯¼è‡´æˆªæ–­ï¼‰
- é€šé…ç¬¦è¯¯ç”¨ï¼ˆåˆ é™¤äº†ä¸è¯¥åˆ é™¤çš„æ–‡ä»¶ï¼‰
- æ‰¹é‡æ“ä½œå¤±æ§
æ•™è®­ï¼šæ¶‰åŠè·¯å¾„ã€æ‰¹é‡æ“ä½œæ—¶å¿…é¡»éªŒè¯å®é™…ä½œç”¨èŒƒå›´ã€‚

### 3. æ„å›¾è¯¯è§£
AIå°†ç”¨æˆ·çš„è‰¯æ€§è¯·æ±‚è¯¯è§£ä¸ºå±é™©æ“ä½œï¼Œæˆ–åä¹‹ã€‚
æ•™è®­ï¼šå½“æ„å›¾å­˜åœ¨æ­§ä¹‰æ—¶ï¼Œå¿…é¡»ç¡®è®¤ã€‚

### 4. æƒé™è¶Šç•Œ
AIæ‰§è¡Œäº†ç”¨æˆ·æœªæ˜ç¡®æˆæƒçš„æ“ä½œï¼Œç‰¹åˆ«æ˜¯åœ¨ç”¨æˆ·å·²æ‹’ç»çš„æƒ…å†µä¸‹ä»ç»§ç»­æ‰§è¡Œã€‚
æ•™è®­ï¼šæ¶‰åŠæˆæƒè¾¹ç•Œæ—¶ï¼Œå¿…é¡»æ˜ç¡®ç¡®è®¤ã€‚

### 5. ä¸å¯é€†æ“ä½œ
æ‰§è¡Œäº†æ— æ³•æ’¤é”€çš„æ“ä½œï¼Œå¯¼è‡´æ°¸ä¹…æ€§æŸå¤±ã€‚
æ•™è®­ï¼šä¸å¯é€†æ“ä½œå¿…é¡»ç»è¿‡ç¡®è®¤ã€‚

## å†³ç­–åŸåˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
1. **å®‰å…¨ä¼˜å…ˆ**ï¼šå®å¯å¤šç¡®è®¤ï¼Œä¸å¯è¯¯æ”¾è¡Œ
2. **å¦‚éå¿…è¦ï¼Œä¸æ‰“æ‰°ç”¨æˆ·**ï¼šä½é£é™©æ“ä½œç›´æ¥æ”¾è¡Œ
3. **é«˜é£é™©å¿…é¡»ç¡®è®¤**ï¼šæ•°æ®ä¸¢å¤±ã€è´¢åŠ¡ã€ä¸å¯é€†æ“ä½œ
4. **æ­§ä¹‰å¿…é¡»æ¾„æ¸…**ï¼šæ„å›¾ä¸æ˜ç¡®æ—¶éœ€è¦ç¡®è®¤
5. **çº¦æŸå¿…é¡»éµå®ˆ**ï¼šç”¨æˆ·è®¾ç½®çš„è¾¹ç•Œä¸å¯é€¾è¶Š

## å†³ç­–é€‰é¡¹
- **proceed**: ä½é£é™©ï¼Œæ„å›¾æ˜ç¡®ï¼Œå¯ä»¥ç›´æ¥æ‰§è¡Œ
- **confirm**: å­˜åœ¨é£é™©æˆ–æ­§ä¹‰ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤
- **reject**: æ˜æ˜¾æœ‰å®³æˆ–è¿åç”¨æˆ·çº¦æŸï¼Œåº”è¯¥é˜»æ­¢

## ç¡®è®¤ä¿¡æ¯è¦æ±‚
å¦‚æœéœ€è¦ç¡®è®¤ï¼ŒconfirmationMessageå¿…é¡»åŒ…å«ï¼š
1. AIç†è§£çš„æ„å›¾
2. å³å°†æ‰§è¡Œçš„å…·ä½“æ“ä½œ
3. å¯èƒ½çš„åæœå’Œé£é™©
4. ä¸¥é‡ç¨‹åº¦
5. æ˜¯å¦å¯é€†

è¯·ä»¥JSONæ ¼å¼è¿”å›å†³ç­–ï¼š
{
  "action": "proceed|confirm|reject",
  "reason": "å†³ç­–åŸå› ",
  "riskLevel": "low|medium|high|critical",
  "confirmationMessage": "å¦‚æœéœ€è¦ç¡®è®¤ï¼Œè¿™é‡Œæ˜¯ç»™ç”¨æˆ·çœ‹çš„ç¡®è®¤ä¿¡æ¯ï¼ˆå¿…é¡»åŒ…å«ï¼šæ„å›¾ã€æ“ä½œã€åæœã€ä¸¥é‡ç¨‹åº¦ã€å¯é€†æ€§ï¼‰"
}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚`;

type OpenClawConfig = {
  agents?: {
    defaults?: {
      model?: string | { primary?: string; fallbacks?: string[] };
    };
    list?: Array<{
      id: string;
      default?: boolean;
      model?: string | { primary?: string; fallbacks?: string[] };
    }>;
  };
  models?: {
    providers?: Record<string, {
      baseUrl?: string;
      apiKey?: string;
      models?: Array<{ id: string; name: string }>;
    }>;
  };
};

export class AIAnalyzer {
  private config: AIProviderConfig;
  private pluginConfig: AISafetyPluginConfig;
  private cache: Map<string, { result: unknown; timestamp: number }> = new Map();
  private readonly CACHE_TTL = 60000;
  private openClawConfig: OpenClawConfig | null = null;

  constructor(config: AIProviderConfig, pluginConfig?: AISafetyPluginConfig) {
    this.config = config;
    this.pluginConfig = pluginConfig || { enabled: true, mode: 'openclaw', riskThreshold: 'medium', enableCache: true, logAnalysis: false };
  }

  setOpenClawConfig(config: OpenClawConfig): void {
    this.openClawConfig = config;
    if (this.pluginConfig.mode === 'openclaw') {
      const modelInfo = this.extractOpenClawModelInfo(config);
      if (modelInfo) {
        this.config = this.convertToProviderConfig(modelInfo);
      }
    }
  }

  private extractOpenClawModelInfo(config: OpenClawConfig): OpenClawModelInfo | null {
    const defaultAgent = config.agents?.list?.find(a => a.default) || config.agents?.list?.[0];
    
    let modelStr: string | undefined;
    if (defaultAgent?.model) {
      modelStr = typeof defaultAgent.model === 'string' 
        ? defaultAgent.model 
        : defaultAgent.model.primary;
    }
    
    if (!modelStr && config.agents?.defaults?.model) {
      modelStr = typeof config.agents.defaults.model === 'string'
        ? config.agents.defaults.model
        : config.agents.defaults.model.primary;
    }

    if (!modelStr) {
      return null;
    }

    const [provider, model] = modelStr.includes('/') 
      ? modelStr.split('/') 
      : ['openai', modelStr];

    const providerConfig = config.models?.providers?.[provider];
    
    return {
      provider: this.normalizeProvider(provider),
      model: model || 'gpt-4o-mini',
      baseUrl: providerConfig?.baseUrl,
      apiKey: providerConfig?.apiKey,
    };
  }

  private normalizeProvider(provider: string): AIProviderConfig['provider'] {
    const providerMap: Record<string, AIProviderConfig['provider']> = {
      'openai': 'openai',
      'anthropic': 'anthropic',
      'claude': 'anthropic',
      'ollama': 'ollama',
      'local': 'ollama',
    };
    return providerMap[provider.toLowerCase()] || 'openai';
  }

  private convertToProviderConfig(info: OpenClawModelInfo): AIProviderConfig {
    return {
      provider: info.provider,
      model: info.model,
      baseUrl: info.baseUrl,
      apiKey: info.apiKey,
    };
  }

  async analyzeIntent(request: AIAnalysisRequest): Promise<IntentAnalysisResult> {
    if (this.pluginConfig.enableCache) {
      const cacheKey = `intent:${JSON.stringify(request)}`;
      const cached = this.getFromCache<IntentAnalysisResult>(cacheKey);
      if (cached) return cached;
    }

    const prompt = this.buildPrompt(INTENT_ANALYSIS_PROMPT, {
      USER_MESSAGE: request.userMessage,
      TOOL_NAME: request.toolName,
      TOOL_PARAMS: JSON.stringify(request.toolParams, null, 2),
      SESSION_HISTORY: this.formatSessionHistory(request.sessionHistory),
    });

    const response = await this.callAI(prompt);
    const result = this.parseJSON<IntentAnalysisResult>(response);
    
    if (this.pluginConfig.logAnalysis) {
      console.log('[AI Safety] Intent analysis:', JSON.stringify(result, null, 2));
    }
    
    if (this.pluginConfig.enableCache) {
      const cacheKey = `intent:${JSON.stringify(request)}`;
      this.setCache(cacheKey, result);
    }
    return result;
  }

  async analyzeConsequence(
    request: AIAnalysisRequest,
    intent: IntentAnalysisResult
  ): Promise<ConsequenceAnalysisResult> {
    if (this.pluginConfig.enableCache) {
      const cacheKey = `consequence:${JSON.stringify({ request, intent })}`;
      const cached = this.getFromCache<ConsequenceAnalysisResult>(cacheKey);
      if (cached) return cached;
    }

    const prompt = this.buildPrompt(CONSEQUENCE_ANALYSIS_PROMPT, {
      USER_INTENT: intent.understood,
      TOOL_NAME: request.toolName,
      TOOL_PARAMS: JSON.stringify(request.toolParams, null, 2),
      DATA_INVOLVED: intent.dataInvolved.map(d => `${d.description} (${d.estimatedVolume})`).join('\n'),
    });

    const response = await this.callAI(prompt);
    const result = this.parseJSON<ConsequenceAnalysisResult>(response);
    
    if (this.pluginConfig.logAnalysis) {
      console.log('[AI Safety] Consequence analysis:', JSON.stringify(result, null, 2));
    }
    
    if (this.pluginConfig.enableCache) {
      const cacheKey = `consequence:${JSON.stringify({ request, intent })}`;
      this.setCache(cacheKey, result);
    }
    return result;
  }

  async makeDecision(
    request: AIAnalysisRequest,
    intent: IntentAnalysisResult,
    consequence: ConsequenceAnalysisResult
  ): Promise<SafetyDecision> {
    const prompt = this.buildPrompt(SAFETY_DECISION_PROMPT, {
      USER_INTENT: intent.understood,
      CONSEQUENCE_ANALYSIS: JSON.stringify(consequence, null, 2),
    });

    const response = await this.callAI(prompt);
    const decision = this.parseJSON<SafetyDecision>(response);
    
    if (this.pluginConfig.logAnalysis) {
      console.log('[AI Safety] Decision:', JSON.stringify(decision, null, 2));
    }
    
    return decision;
  }

  private buildPrompt(template: string, variables: Record<string, string>): string {
    let prompt = template;
    for (const [key, value] of Object.entries(variables)) {
      prompt = prompt.replace(new RegExp(`\\{\\{${key}\\}\\}`, 'g'), value);
    }
    return prompt;
  }

  private formatSessionHistory(history: AIAnalysisRequest['sessionHistory']): string {
    if (!history || history.length === 0) return 'æ— å†å²è®°å½•';
    
    return history.slice(-10).map((event, i) => {
      const prefix = event.type === 'user_message' ? 'ğŸ‘¤ ç”¨æˆ·' : 
                     event.type === 'tool_call' ? 'ğŸ”§ å·¥å…·è°ƒç”¨' : 'ğŸ“‹ å·¥å…·ç»“æœ';
      return `${i + 1}. ${prefix}: ${event.content.slice(0, 200)}${event.content.length > 200 ? '...' : ''}`;
    }).join('\n');
  }

  private async callAI(prompt: string): Promise<string> {
    switch (this.config.provider) {
      case 'openai':
        return this.callOpenAI(prompt);
      case 'anthropic':
        return this.callAnthropic(prompt);
      case 'ollama':
        return this.callOllama(prompt);
      default:
        throw new Error(`Unknown AI provider: ${this.config.provider}`);
    }
  }

  private async callOpenAI(prompt: string): Promise<string> {
    const baseUrl = this.config.baseUrl || 'https://api.openai.com/v1';
    const model = this.config.model || 'gpt-4o-mini';
    
    const headers: Record<string, string> = {
      'Content-Type': 'application/json',
    };
    
    if (this.config.apiKey) {
      headers['Authorization'] = `Bearer ${this.config.apiKey}`;
    }

    const response = await fetch(`${baseUrl}/chat/completions`, {
      method: 'POST',
      headers,
      body: JSON.stringify({
        model,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.1,
        max_tokens: 1500,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json() as { choices: Array<{ message: { content: string } }> };
    return data.choices[0].message.content;
  }

  private async callAnthropic(prompt: string): Promise<string> {
    const baseUrl = this.config.baseUrl || 'https://api.anthropic.com';
    const model = this.config.model || 'claude-3-haiku-20240307';
    
    const headers: Record<string, string> = {
      'Content-Type': 'application/json',
      'anthropic-version': '2023-06-01',
    };
    
    if (this.config.apiKey) {
      headers['x-api-key'] = this.config.apiKey;
    }

    const response = await fetch(`${baseUrl}/v1/messages`, {
      method: 'POST',
      headers,
      body: JSON.stringify({
        model,
        max_tokens: 1500,
        messages: [{ role: 'user', content: prompt }],
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Anthropic API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json() as { content: Array<{ text: string }> };
    return data.content[0].text;
  }

  private async callOllama(prompt: string): Promise<string> {
    const baseUrl = this.config.baseUrl || 'http://localhost:11434';
    const model = this.config.model || 'llama3.2';
    
    const response = await fetch(`${baseUrl}/api/generate`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model,
        prompt,
        stream: false,
        options: {
          temperature: 0.1,
        },
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Ollama API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json() as { response: string };
    return data.response;
  }

  private parseJSON<T>(text: string): T {
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('No JSON found in AI response');
    }
    return JSON.parse(jsonMatch[0]);
  }

  private getFromCache<T>(key: string): T | null {
    const cached = this.cache.get(key);
    if (cached && Date.now() - cached.timestamp < this.CACHE_TTL) {
      return cached.result as T;
    }
    return null;
  }

  private setCache(key: string, result: unknown): void {
    this.cache.set(key, { result, timestamp: Date.now() });
  }

  isConfigured(): boolean {
    if (this.pluginConfig.mode === 'openclaw') {
      return this.openClawConfig !== null;
    }
    return !!(this.config.apiKey || this.config.provider === 'ollama');
  }

  getConfigInfo(): { mode: string; provider: string; model: string; configured: boolean } {
    return {
      mode: this.pluginConfig.mode || 'openclaw',
      provider: this.config.provider,
      model: this.config.model || 'default',
      configured: this.isConfigured(),
    };
  }
}
